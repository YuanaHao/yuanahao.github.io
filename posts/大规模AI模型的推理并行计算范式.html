<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
  <head>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="keywords" content="自我提升,效率提升,开源工具,学习笔记" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #252232);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://newzone.top/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1AI%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E8%8C%83%E5%BC%8F.html"><meta property="og:site_name" content="CS_Blog"><meta property="og:title" content="大规模AI模型的infer并行计算范式"><meta property="og:description" content="Abstract 随着models参数规模进入万亿级别，其在infer阶段的部署面临 memery bound、compute bound与I/O bound等多重挑战。本文旨在系统性地梳理和剖析大规模模型infer所采用的高性能并行计算范式。首先界定DP PP TP概念及其在推理场景下的应用边界与理论局限。其次，深入探讨了以Continuous Ba..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-06-23T04:22:38.000Z"><meta property="article:tag" content="分布式系统"><meta property="article:tag" content="MLSys"><meta property="article:tag" content="并行运算"><meta property="article:modified_time" content="2025-06-23T04:22:38.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"大规模AI模型的infer并行计算范式","image":[""],"dateModified":"2025-06-23T04:22:38.000Z","author":[]}</script><link rel="alternate" type="application/atom+xml" href="https://newzone.top/atom.xml" title="CS_Blog Atom Feed"><link rel="alternate" type="application/json" href="https://newzone.top/feed.json" title="CS_Blog JSON Feed"><link rel="alternate" type="application/rss+xml" href="https://newzone.top/rss.xml" title="CS_Blog RSS Feed"><link rel="icon" href="/favicon.ico"><title>大规模AI模型的infer并行计算范式 | CS_Blog</title><meta name="description" content="Abstract 随着models参数规模进入万亿级别，其在infer阶段的部署面临 memery bound、compute bound与I/O bound等多重挑战。本文旨在系统性地梳理和剖析大规模模型infer所采用的高性能并行计算范式。首先界定DP PP TP概念及其在推理场景下的应用边界与理论局限。其次，深入探讨了以Continuous Ba...">
    <link rel="stylesheet" href="/assets/css/styles.e385fbb8.css">
    <link rel="preload" href="/assets/js/runtime~app.be408f8f.js" as="script"><link rel="preload" href="/assets/css/styles.e385fbb8.css" as="style"><link rel="preload" href="/assets/js/7032.15ec0d1f.js" as="script"><link rel="preload" href="/assets/js/app.60c20e90.js" as="script">
    
    <!-- 统计代码区域-->
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">CS_Blog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/blog.html" aria-label="博客"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa6-solid:blog" width="1em" height="1em"></iconify-icon><!--]-->博客<!----></a></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/YuanaHao" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="search-pro-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa6-solid:feather-pointed" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/blog.html" aria-label="博客文章"><!---->博客文章<!----></a><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/CSE234.html" aria-label="/posts/CSE234.html"><!---->/posts/CSE234.html<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/PA.html" aria-label="PA -- A new journey for the OS"><!---->PA -- A new journey for the OS<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/CSE234_PA.html" aria-label="CSE234"><!---->CSE234<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1AI%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E8%8C%83%E5%BC%8F.html" aria-label="大规模AI模型的infer并行计算范式"><!---->大规模AI模型的infer并行计算范式<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/0_REPORT.html" aria-label="ASC2025 TEST_0_CONCURRENCY"><!---->ASC2025 TEST_0_CONCURRENCY<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/1_REPORT.html" aria-label="ASC2025 TEST_1_cluster"><!---->ASC2025 TEST_1_cluster<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/CS61A.html" aria-label="CS61A"><!---->CS61A<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E6%96%87%E7%94%9F%E5%9B%BE.html" aria-label="Diffusion（文生图、文生视频）推理服务"><!---->Diffusion（文生图、文生视频）推理服务<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/MLSys_%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%88%E9%80%89%E8%AF%BB).html" aria-label="MLSys_分布式开发（选读）"><!---->MLSys_分布式开发（选读）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/AISys_%E5%88%86%E5%B8%83%E5%BC%8F.html" aria-label="MLSys_分布式开发"><!---->MLSys_分布式开发<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/CS149_asst1.html" aria-label="CS149 Lab Assignment1"><!---->CS149 Lab Assignment1<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/factorial_Stirling.html" aria-label="阶乘的位数估算--数学在计算机算法研究中的作用"><!---->阶乘的位数估算--数学在计算机算法研究中的作用<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/vjudge_solutions_1.html" aria-label="ACM Try -- 01"><!---->ACM Try -- 01<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/What_is_Automatic_Differentiation.html" aria-label="What&#39;s Automatic Differentiation?"><!---->What&#39;s Automatic Differentiation?<!----></a></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->大规模AI模型的infer并行计算范式</h1><div class="page-info"><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color3 clickable" role="navigation">SOSD</span><!--]--><meta property="articleSection" content="SOSD"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color8 clickable" role="navigation">分布式系统</span><span class="page-tag-item color8 clickable" role="navigation">MLSys</span><span class="page-tag-item color1 clickable" role="navigation">并行运算</span><!--]--><meta property="keywords" content="分布式系统,MLSys,并行运算"></span><span class="page-word-info" aria-label="字数🔠" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon" name="word"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>约 2463 字</span><meta property="wordCount" content="2463"></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 8 分钟</span><meta property="timeRequired" content="PT8M"></span><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#abstract">Abstract</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract"><span><strong>Abstract</strong></span></a></h2><p>随着models参数规模进入万亿级别，其在infer阶段的部署面临 <code>memery bound</code>、<code>compute bound</code>与<code>I/O bound</code>等多重挑战。本文旨在系统性地梳理和剖析大规模模型infer所采用的高性能并行计算范式。首先界定<code>DP</code> <code>PP</code> <code>TP</code>概念及其在推理场景下的应用边界与理论局限。其次，深入探讨了以<code>Continuous Batching</code>和<code>PagedAttention</code>为代表的现代推理系统的核心架构演进。在此基础上，本文进一步剖析了<code>Quantization</code>、<code>Speculative Decoding</code>等前沿算法优化。为将理论与实践相结合，本文选取了三个典型案例进行深度研究：面向特定架构的组件级并行（以Stable Diffusion为例）、应对超长上下文挑战的序列并行，以及在复杂单一样本场景下的混合并行策略（以AlphaFold3为例）。最后，通过一个在HPC环境下部署CPU推理集群的工程案例，展示了在现实约束下进行系统架构设计的智慧。本文期望为从事大规模AI infra的researcher和engineer提供一个清晰、全面的知识图谱与决策参考。</p><hr><h4 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction"><span><strong>Introduction</strong></span></a></h4><ol><li><strong>infer成为新的瓶颈</strong><ul><li>后训练时代（Post-Training Era）的来临：模型即服务（Model-as-a-Service）的兴起</li><li>推理阶段的三大核心挑战： <ul><li><strong>Memory Wall</strong>：模型权重与动态KV缓存的巨大内存占用。</li><li><strong>Compute Wall</strong>：自回归解码带来的序列化计算与单次前向传播的巨大浮点运算量（FLOPs）。</li><li><strong>Throughput Wall</strong>：在满足严格Latency约束下，最大化并发处理能力的经济性问题。</li></ul></li></ul></li><li><strong>constrution and contribution</strong><ul><li>系统性构建推理并行的class。</li><li>深入分析关键系统优化与算法优化的内在机理。</li><li>通过前沿案例研究，展示多维并行策略的综合应用。</li><li>提供一个从理论到工程实践的完整审视视角。</li></ul></li></ol><h4 id="第一章-推理并行的基础范式与理论边界" tabindex="-1"><a class="header-anchor" href="#第一章-推理并行的基础范式与理论边界"><span><strong>第一章：推理并行的基础范式与理论边界</strong></span></a></h4><p>1.1. <strong>张量并行 (Tensor Parallelism, TP): 降低计算延迟的核心手段</strong></p><blockquote><p>Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism https://arxiv.org/abs/1909.08053. How to Train Really Large Models on Many GPUs? https://lilianweng.github.io/posts/2021-09-25-train-large/</p></blockquote><ul><li><strong>核心思想</strong>：算子内部（Intra-Operator）的并行化，将单个计算密集型算子（如GEMM）切分至多个计算单元。</li><li><strong>数学原理</strong>：基于矩阵乘法结合律的行、列切分策略。 <ul><li>矩阵拆分：在神经网络层内部，将权重矩阵按行或列进行切分，分布到不同GPU上。（主要是Self-Attention层和MLP层）</li><li>局部计算：每个GPU仅存储所分配的参数量，执行局部的矩阵乘法运算</li><li>通信同步： <ul><li>列并行：通过 All-Gather 将不同GPU的输出部分进行拼接（如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>X</mi><msub><mi>W</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>X</mi><msub><mi>W</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[X W_{1},X W_{2}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>）</li><li>行并行：通过 All-Reduce 对部分结果求和（如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>X</mi><mn>2</mn></msub><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_{1}W_{1}+X_{2}W_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>​）</li></ul></li></ul></li></ul><p><img src="/assets/img/TP.404b53db.png" alt=""></p><ul><li><strong>应用与理论局限</strong>：对节点内高带宽通信（如NVLink）有强依赖性；通信开销随并行度增加而上升，存在扩展性边界。</li></ul><p>1.2. <strong>模型并行 (Model Parallelism, MP): 低显存占用但并不高效</strong> * <strong>核心思想</strong>：computation 和 model 参数在多台计算机上进行分区。与每个 worker 托管整个模型的完整副本的数据并行性不同，MP 仅在一个 worker 上分配一小部分模型参数，因此内存使用和计算量都减少了。 * <strong>主要缺陷</strong>：通过具有顺序依赖关系的多个此类 worker 运行每个数据批次的都会导致微观上的串行。 * <strong>实现示意</strong>： <img src="/assets/img/DP.c0f8d8bc.png" alt=""></p><p>1.3. <strong>流水线并行 (Pipeline Parallelism, PP): 提升硬件利用率与吞吐量的关键</strong> * <strong>核心思想</strong>：算子间（Inter-Operator）的并行化，将模型的计算图（Computational Graph）按层（Stage）切分。 * <strong>计算模型</strong>：微批处理（Micro-batching）与流水线调度，分析“流水线气泡”（Pipeline Bubble）的成因与影响。 * <strong>应用与理论局限</strong>：无法降低单一样本的端到端延迟；负载均衡（Load Balancing）是关键挑战；气泡开销限制了其在小批量或低延迟场景下的效率。</p><p>1.4. <strong>数据并行 (Data Parallelism, DP): 服务能力水平扩展的直接范式</strong> * <strong>核心思想</strong>：通过模型副本（Model Replication）实现请求级并行。 * <strong>架构模式</strong>：负载均衡器（Load Balancer） + 多个独立推理副本。 * <strong>应用与理论局限</strong>：无法解决单模型内存或计算瓶颈；成本随副本数线性增长；不适用于<code>batch_size=1</code>的场景。</p><h4 id="第二章-现代推理系统的核心技术与架构演进" tabindex="-1"><a class="header-anchor" href="#第二章-现代推理系统的核心技术与架构演进"><span><strong>第二章：现代推理系统的核心技术与架构演进</strong></span></a></h4><p>2.1. <strong>架构范式：混合并行 (Hybrid Parallelism)</strong> * <strong>设计哲学</strong>：节点内TP + 节点间PP，最大化利用异构的通信带宽层级。 * <strong>典型架构</strong>：以Megatron-LM的部署架构为例，分析其通信模式。</p><p>2.2. <strong>I/O与内存管理优化：从根本上提升系统效率</strong> * <strong>调度革命：连续批处理 (Continuous Batching)</strong>：将静态、离散的批处理，演进为动态、连续的请求流处理，从调度层面消除GPU空闲。 * <strong>内存革命：分页注意力 (PagedAttention)</strong>：借鉴操作系统虚拟内存思想，将逻辑上连续的KV缓存存储在物理上非连续的内存块（Block）中，从根本上解决内存碎片问题。</p><h4 id="第三章-前沿算法优化-突破性能瓶颈" tabindex="-1"><a class="header-anchor" href="#第三章-前沿算法优化-突破性能瓶颈"><span><strong>第三章：前沿算法优化：突破性能瓶颈</strong></span></a></h4><p>3.1. <strong>模型压缩与量化 (Model Compression &amp; Quantization)</strong> * <strong>原理</strong>：通过降低权重和/或激活值的数值精度，减少内存占用与计算量。 * <strong>主流方法评述</strong>：从GPTQ到AWQ，分析其如何在保持模型精度的前提下进行有效量化。</p><p>3.2. <strong>解码加速：推测解码 (Speculative Decoding)</strong> * <strong>原理</strong>：利用轻量级草稿模型（Draft Model）与原始目标模型（Target Model）的验证机制，打破自回归解码“一次生成一个Token”的序列化限制。 * <strong>性能模型分析</strong>：分析其加速效果与草稿模型接受率（Acceptance Rate）之间的关系。</p><h4 id="第四章-特定领域并行策略剖析-案例研究-case-studies" tabindex="-1"><a class="header-anchor" href="#第四章-特定领域并行策略剖析-案例研究-case-studies"><span><strong>第四章：特定领域并行策略剖析：案例研究 (Case Studies)</strong></span></a></h4><p>4.1. <strong>案例一：组件级与任务级并行——以Stable Diffusion为例</strong> * <strong>问题域</strong>：文生图模型的多阶段、异构计算特性。 * <strong>解决方案</strong>：构建“宏观流水线”（Macro-pipeline），将Text Encoder, U-Net, VAE Decoder等独立组件部署于不同硬件单元，实现组件级的流水线并行，最大化图像生成吞吐量。</p><p>4.2. <strong>案例二：序列并行 (Sequence Parallelism)——应对超长上下文挑战</strong> * <strong>问题域</strong>：注意力机制中<code>O(N²)</code>的内存复杂度成为处理长序列的根本瓶颈。 * <strong>解决方案</strong>：沿序列维度对张量及计算进行切分，通过与张量并行协同的通信策略（如Reduce-Scatter, All-Gather），避免在单设备上实例化完整的注意力矩阵。</p><p>4.3. <strong>案例三：复杂单一样本的混合并行——AlphaFold3的系统设计启示</strong> * <strong>问题域</strong>：<code>batch_size=1</code>的场景下，DDP失效，如何对单个“超级样本”进行并行计算？ * <strong>多维度并行策略剖析</strong>： * <strong>模型内部并行 (Intra-Model)</strong>：TP（Head/Dimension并行）与PP是基础。 * <strong>算法流程并行 (Inter-Task)</strong>：利用DiT模块多次独立采样的特性，进行任务级并行（Task Parallelism）。 * <strong>硬件内核级优化 (Kernel-Level)</strong>：采用序列感知的算子调度策略，动态选择SDPA、FlashAttention或更前沿的SageAttention等最高效的注意力计算内核。</p><h4 id="第五章-工程实践的智慧-当理论框架遇到现实约束" tabindex="-1"><a class="header-anchor" href="#第五章-工程实践的智慧-当理论框架遇到现实约束"><span><strong>第五章：工程实践的智慧：当理论框架遇到现实约束</strong></span></a></h4><ul><li><strong>案例背景</strong>：在基于SLURM的纯CPU HPC集群上，规模化部署基于vLLM的DeepSeek模型。</li><li><strong>面临的约束</strong>：vLLM的CPU后端功能受限（无TP/PP），且其分布式后端Ray与HPC生态不兼容。</li><li><strong>架构设计：服务层并行化与解耦编排</strong><ul><li><strong>核心思路</strong>：构建一个由SGLang Router作为统一入口，SLURM作为资源调度与进程管理器的解耦式架构。</li><li><strong>架构解析</strong>：该架构在服务层实现了请求的负载均衡与并行处理，有效绕开了底层框架的限制。这是一个典型的“以系统架构设计弥补框架能力不足”的工程范例。</li></ul></li><li><strong>单节点优化策略</strong>：结合AWQ量化和投机解码，分别针对CPU环境下的内存带宽和单样本延迟瓶颈进行优化。</li></ul><h4 id="结论与展望" tabindex="-1"><a class="header-anchor" href="#结论与展望"><span><strong>结论与展望</strong></span></a></h4><ol><li><strong>构建决策框架</strong>：总结一张决策图或表格，为从业者在面对不同业务目标（延迟、吞吐量、成本）和技术挑战（模型大小、序列长度）时，如何选择与组合不同的并行及优化技术提供指导。</li><li><strong>未来展望</strong>： <ul><li><strong>自动化并行 (Automated Parallelism)</strong>：自动并行策略搜索与编译优化。</li><li><strong>软硬件协同设计 (Hardware-Software Co-design)</strong>：面向未来AI硬件的算法与系统架构。</li><li><strong>新计算范式</strong>：探索非Transformer架构（如Mamba, RWKV）的并行潜力。</li></ul></li></ol></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/CSE234_PA.html" aria-label="CSE234"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->CSE234</div></a><a class="route-link auto-link next" href="/posts/0_REPORT.html" aria-label="ASC2025 TEST_0_CONCURRENCY"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">ASC2025 TEST_0_CONCURRENCY<!----></div></a></nav><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">
  版权声明：自由转载 - 非商用 - 非衍生 - 保持署名<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" target="_blank" rel="noopener noreferrer">（创意共享 4.0 许可证）</a>|
  Copyright © 2024-present YuanaHao</a>
  </div></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.be408f8f.js" defer></script><script src="/assets/js/7032.15ec0d1f.js" defer></script><script src="/assets/js/app.60c20e90.js" defer></script>
    <!-- 看板娘区块 -->
    <script src="/live2d-widget/autoload.js"></script>
    <!-- End 看板娘区块 -->
  </body>
</html>
